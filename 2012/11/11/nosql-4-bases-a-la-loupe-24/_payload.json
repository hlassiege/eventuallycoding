[{"data":1,"prerenderedAt":829},["Reactive",2],{"/articles/2012/11/11/nosql-4-bases-a-la-loupe-24":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":7,"title":8,"description":9,"id":10,"date":11,"categories":12,"tags":14,"img":18,"cover":19,"readingTime":20,"body":25,"_type":824,"_id":825,"_source":826,"_file":827,"_extension":828},"/articles/2012/11/11/nosql-4-bases-a-la-loupe-24","11",false,"","Nosql, 4 bases à la loupe 2/4","[![](/images/nosql-logo.gif \"nosql-logo\")](http://hakanai.free.fr/index.php/nosql-4-bases-a-la-loupe-14/nosql-logo/)Vous vous rappelez du bouquin [7 d...","666","2012-11-11",[13],"waza",[15,16,17],"lucene","mongodb","redis","nosql-logo.gif","cover2.jpg",{"text":21,"minutes":22,"time":23,"words":24},"10 min read",9.61,576600,1922,{"type":26,"children":27,"toc":817},"root",[28,58,83,98,108,117,139,144,149,154,164,172,177,199,204,212,217,222,232,237,242,253,258,265,278,283,291,296,310,351,356,361,374,379,397,403,414,423,435,440,445,456,461,466,472,477,528,538,543,551,557,562,612,617,627,632,640,645,657,663,668,673,678,691,704,723,728,736,741,746,759,764,769,774],{"type":29,"tag":30,"props":31,"children":32},"element","p",{},[33,46,49,56],{"type":29,"tag":34,"props":35,"children":39},"a",{"href":36,"rel":37},"http://hakanai.free.fr/index.php/nosql-4-bases-a-la-loupe-14/nosql-logo/",[38],"nofollow",[40],{"type":29,"tag":41,"props":42,"children":45},"img",{"alt":7,"src":43,"title":44},"/images/nosql-logo.gif","nosql-logo",[],{"type":47,"value":48},"text","Vous vous rappelez du bouquin ",{"type":29,"tag":34,"props":50,"children":53},{"href":51,"rel":52},"http://pragprog.com/book/rwdata/seven-databases-in-seven-weeks",[38],[54],{"type":47,"value":55},"7 databases in seven weeks",{"type":47,"value":57}," ? Pour le coup j'ai eu l'occasion de réaliser une expérience un peu moins ambitieuse, seulement 4 bases de données. Et si je n'ai pas été aussi loin que le bouquin précédent je vous propose quand même un retour d'expérience sur :",{"type":29,"tag":59,"props":60,"children":61},"ul",{},[62,68,73,78],{"type":29,"tag":63,"props":64,"children":65},"li",{},[66],{"type":47,"value":67},"Redis",{"type":29,"tag":63,"props":69,"children":70},{},[71],{"type":47,"value":72},"Solr",{"type":29,"tag":63,"props":74,"children":75},{},[76],{"type":47,"value":77},"Elastic Search",{"type":29,"tag":63,"props":79,"children":80},{},[81],{"type":47,"value":82},"MongoDb",{"type":29,"tag":30,"props":84,"children":85},{},[86,88,96],{"type":47,"value":87},"Ce billet fait partie d'une série de plusieurs billets dont le premier est ",{"type":29,"tag":34,"props":89,"children":93},{"href":90,"rel":91,"title":92},"http://hakanai.free.fr/index.php/nosql-4-bases-a-la-loupe-14/",[38],"Nosql, 4 bases à la loupe 1/4",[94],{"type":47,"value":95},"ici",{"type":47,"value":97},". Et le sujet de celui-ci est MongoDb et Redis.",{"type":29,"tag":99,"props":100,"children":101},"h3",{"id":17},[102],{"type":29,"tag":34,"props":103,"children":106},{"href":104,"rel":105},"http://redis.io/",[38],[107],{"type":47,"value":67},{"type":29,"tag":30,"props":109,"children":110},{},[111],{"type":29,"tag":112,"props":113,"children":114},"em",{},[115],{"type":47,"value":116},"Note : Redis n'est pas disponible sur Windows du coup j'ai du prendre une version non officielle pour tester.",{"type":29,"tag":30,"props":118,"children":119},{},[120,122,129,131,137],{"type":47,"value":121},"C'est la première base de données que j'ai testé sous les conseils de ",{"type":29,"tag":34,"props":123,"children":126},{"href":124,"rel":125},"https://fr.twitter.com/jblemee",[38],[127],{"type":47,"value":128},"Jean Baptiste Lemée",{"type":47,"value":130},". Il s'agit avant tout d'un stockage ",{"type":29,"tag":132,"props":133,"children":134},"strong",{},[135],{"type":47,"value":136},"clé-valeur",{"type":47,"value":138}," mais il permet aussi de manipuler des listes et des sets. On hésite parfois à la considérer comme une base de données et plus comme un cache.",{"type":29,"tag":30,"props":140,"children":141},{},[142],{"type":47,"value":143},"Et pourtant c'est bien une base de données, les données sont persisté sur disque.",{"type":29,"tag":30,"props":145,"children":146},{},[147],{"type":47,"value":148},"Sur le chapitre des fonctionnalités Redis, malgré le fait qu'il soit rangé dans la catégorie des bases clé valeurs, reste assez riche. On pourra gérer des transactions, enchaîner des commandes (pipeline), gérer des listes ou des sets. Sur le papier c'est donc pas mal : rapide, fonctionnellement plus riche que d'autres équivalents clé-valeur. Mais malgré tout on est quand même loin de la richesse fonctionnelle attendue, pas de recherche full text ou de géospatial et surtout une représentation des données qui va nous obliger à pas mal de gymnastique.",{"type":29,"tag":30,"props":150,"children":151},{},[152],{"type":47,"value":153},"Avec ce mode de stockage, il faut être imaginatif et changer sa façon de concevoir ces modèles de données. Notamment il faut penser \"dénormalisation\".",{"type":29,"tag":30,"props":155,"children":156},{},[157,162],{"type":29,"tag":132,"props":158,"children":159},{},[160],{"type":47,"value":161},"Explication.",{"type":47,"value":163}," Redis est orienté clé valeur donc même si nous pouvons stocker notre document sous forme Json il nous sera alors impossible de requêter sur une de ces propriétés, ce n’est donc pas suffisant. Du coup, on va dénormaliser notre objet au maximum et stocker chaque propriété selon des conventions de nommage que nous allons nous fixer. Par exemple pour un objet Profile nous pourrions avoir les records suivants :",{"type":29,"tag":30,"props":165,"children":166},{},[167],{"type":29,"tag":112,"props":168,"children":169},{},[170],{"type":47,"value":171},"\"id:1:login\" => \"loginDuPremierProfile\" \"login:loginDuPremierProfile\" => 1",{"type":29,"tag":30,"props":173,"children":174},{},[175],{"type":47,"value":176},"Ces deux premiers records permettront de rechercher très rapidement o(1) un profile par son login ou bien de connaitre le login du profile d'id 1.",{"type":29,"tag":30,"props":178,"children":179},{},[180],{"type":29,"tag":112,"props":181,"children":182},{},[183,185,191,193,197],{"type":47,"value":184},"\"id:1:email\" => \"",{"type":29,"tag":34,"props":186,"children":188},{"href":187},"mailto:profile@email.com",[189],{"type":47,"value":190},"profile@email.com",{"type":47,"value":192},"\" \"email:",{"type":29,"tag":34,"props":194,"children":195},{"href":187},[196],{"type":47,"value":190},{"type":47,"value":198},"\" => 1",{"type":29,"tag":30,"props":200,"children":201},{},[202],{"type":47,"value":203},"même genre d'exemple avec l'email.",{"type":29,"tag":30,"props":205,"children":206},{},[207],{"type":29,"tag":112,"props":208,"children":209},{},[210],{"type":47,"value":211},"\"profile:1:object\" => représentation JSON de mon objet Profile",{"type":29,"tag":30,"props":213,"children":214},{},[215],{"type":47,"value":216},"Et enfin un dernier record permettant de stocker l'objet entier lorsqu'on veut le récupérer en une seule fois.",{"type":29,"tag":30,"props":218,"children":219},{},[220],{"type":47,"value":221},"Un exemple avec redis-cli en ligne de commande :",{"type":29,"tag":223,"props":224,"children":226},"pre",{"code":225},"\nredis 127.0.0.1:6379> get profile:login1:object\n\"{\"address\":{\"zipCode\":\"1\",\"loc\":[0.0,0.0]},\"_id\":\"login1\"}\"\n",[227],{"type":29,"tag":228,"props":229,"children":230},"code",{"__ignoreMap":7},[231],{"type":47,"value":225},{"type":29,"tag":30,"props":233,"children":234},{},[235],{"type":47,"value":236},"Une recherche par login va donc se faire en plusieurs requêtes :",{"type":29,"tag":30,"props":238,"children":239},{},[240],{"type":47,"value":241},"\"login:loginDuPremierProfile\" va nous renvoyer 1 \"profile:1:object\" va nous renvoyer l'objet sérialisé en json.",{"type":29,"tag":30,"props":243,"children":244},{},[245,247],{"type":47,"value":246},"Je ne vais pas plus loin pour mon exemple mais vous pouvez trouver la liste des opérations possibles sur vos données ici : ",{"type":29,"tag":34,"props":248,"children":251},{"href":249,"rel":250},"http://redis.io/commands",[38],[252],{"type":47,"value":249},{"type":29,"tag":30,"props":254,"children":255},{},[256],{"type":47,"value":257},"Voyons les APIs",{"type":29,"tag":259,"props":260,"children":262},"h4",{"id":261},"jedis",[263],{"type":47,"value":264},"Jedis",{"type":29,"tag":30,"props":266,"children":267},{},[268,270,276],{"type":47,"value":269},"Ce fut a mon sens une erreur en testant Redis, j'ai utilisé ",{"type":29,"tag":34,"props":271,"children":274},{"href":272,"rel":273},"https://github.com/xetorthio/jedis",[38],[275],{"type":47,"value":264},{"type":47,"value":277}," comme client et je suis donc resté très proche du protocole. Sauf qu'il ne s'agit pas du protocole le plus simple.",{"type":29,"tag":30,"props":279,"children":280},{},[281],{"type":47,"value":282},"Voyons par exemple le code pour le cas que j'ai décrit plus haut :",{"type":29,"tag":223,"props":284,"children":286},{"code":285},"\nObjectMapper mapper = new ObjectMapper();\njedis.set(\"fid:\"+profile.getLogin()+\":login\",profile.getLogin());\njedis.set(\"flogin:\"+profile.getLogin(),profile.getLogin());\njedis.set(\"fid:\"+profile.getLogin()+\":zipcode\",profile.getAddress().getZipCode());\njedis.set(\"zipcode:\"+profile.getAddress().getZipCode(), profile.getLogin());\njedis.set(\"profile:\"+profile.getLogin()+\":object\",mapper.writeValueAsString(profile));\njedis.incr(\"profile:count\");\n",[287],{"type":29,"tag":228,"props":288,"children":289},{"__ignoreMap":7},[290],{"type":47,"value":285},{"type":29,"tag":30,"props":292,"children":293},{},[294],{"type":47,"value":295},"Je sens que vous comprenez à quel point les migrations de données vont être galère (par exemple le jour où vous décidez de rajouter une autre propriété disponible pour la recherche...)",{"type":29,"tag":30,"props":297,"children":298},{},[299,301,308],{"type":47,"value":300},"Vous pouvez jeter un oeil sur ",{"type":29,"tag":34,"props":302,"children":305},{"href":303,"rel":304},"https://bitbucket.org/hlassiege/nosql/src/821b12c7c105/src/test/java/com/sandbox/JedisTest.java?at=default",[38],[306],{"type":47,"value":307},"JedisTest",{"type":47,"value":309},", pour moi ce fut une mauvaise entrée en matière. J’ai peu apprécié l’API. Par contre côté perf je n’ai pas été décu :",{"type":29,"tag":30,"props":311,"children":312},{},[313,317,319,324,326,330,332,337,339,343,345,349],{"type":29,"tag":132,"props":314,"children":315},{},[316],{"type":47,"value":307},{"type":47,"value":318},".findByLoginShouldReturnSomething: [measured 10 out of 15 rounds, threads: 1 (sequential)] round: ",{"type":29,"tag":132,"props":320,"children":321},{},[322],{"type":47,"value":323},"0.03",{"type":47,"value":325}," [+- 0.01], round.gc: 0.00 [+- 0.00], GC.calls: 2, GC.time: 0.00, time.total: 57.59, time.warmup: 57.25, time.bench: 0.34 ",{"type":29,"tag":132,"props":327,"children":328},{},[329],{"type":47,"value":307},{"type":47,"value":331},".assertThatMyDatabaseHasMoreThan100Profile: [measured 10 out of 15 rounds, threads: 1 (sequential)] round: ",{"type":29,"tag":132,"props":333,"children":334},{},[335],{"type":47,"value":336},"0.00",{"type":47,"value":338}," [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 0, GC.time: 0.00, time.total: 0.07, time.warmup: 0.03, time.bench: 0.04 ",{"type":29,"tag":132,"props":340,"children":341},{},[342],{"type":47,"value":307},{"type":47,"value":344},".testSearchWithEmbeddedObject: [measured 10 out of 15 rounds, threads: 1 (sequential)] round: ",{"type":29,"tag":132,"props":346,"children":347},{},[348],{"type":47,"value":323},{"type":47,"value":350}," [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 2, GC.time: 0.00, time.total: 0.43, time.warmup: 0.15, time.bench: 0.28",{"type":29,"tag":30,"props":352,"children":353},{},[354],{"type":47,"value":355},"Et surtout, quelque soit la volumétrie ce temps est constant puisqu'on accède à chaque enregistrement par sa clé.",{"type":29,"tag":30,"props":357,"children":358},{},[359],{"type":47,"value":360},"Par la suite on m'a conseillé d'autres apis sans doute plus adapté :",{"type":29,"tag":59,"props":362,"children":363},{},[364,369],{"type":29,"tag":63,"props":365,"children":366},{},[367],{"type":47,"value":368},"Johm",{"type":29,"tag":63,"props":370,"children":371},{},[372],{"type":47,"value":373},"Spring Data",{"type":29,"tag":259,"props":375,"children":377},{"id":376},"johm",[378],{"type":47,"value":368},{"type":29,"tag":30,"props":380,"children":381},{},[382,388,390,395],{"type":29,"tag":34,"props":383,"children":386},{"href":384,"rel":385},"https://github.com/xetorthio/johm",[38],[387],{"type":47,"value":384},{"type":47,"value":389}," J’ai voulu tester Johm car le premier a m’avoir aiguillé vers des Apis plus haut niveau m’avait conseillé Ohm (pour Ruby). Mais malgré l’annonce sur Github : ",{"type":29,"tag":112,"props":391,"children":392},{},[393],{"type":47,"value":394},"JOhm is still in active development.",{"type":47,"value":396},", le dernier commit date de 2 ans... J’ai quand même voulu testé mais Johm n’est pas compatible avec les dernières versions de Redis. Epic fail.",{"type":29,"tag":259,"props":398,"children":400},{"id":399},"spring-data-redis",[401],{"type":47,"value":402},"Spring data Redis",{"type":29,"tag":30,"props":404,"children":405},{},[406,412],{"type":29,"tag":34,"props":407,"children":410},{"href":408,"rel":409},"http://www.springsource.org/spring-data/redis",[38],[411],{"type":47,"value":408},{"type":47,"value":413}," Pour le coup même si j’utilise Spring depuis 2006 et que j’en ai été un grand fan, aujourd’hui je n’avais pas envie de faire entrer le loup dans la bergerie. Je serais ravi d’approfondir le fond de ma pensée autour d’un verre, mais ce n’est pas le sujet de ce billet. Bon, malgré tout si j’avais choisi Redis, ce que je n’ai pas fait au final, je pense que ca aurait été l’API à choisir.",{"type":29,"tag":99,"props":415,"children":416},{"id":16},[417],{"type":29,"tag":34,"props":418,"children":421},{"href":419,"rel":420},"http://www.mongodb.org/",[38],[422],{"type":47,"value":82},{"type":29,"tag":30,"props":424,"children":425},{},[426,428,433],{"type":47,"value":427},"MongoDb fait partie de la famille des bases Nosql orienté document. Plus riche fonctionnellement que Redis on va notamment trouver le support des recherches géospatiales, des fonctions d’aggrégation, le stockage de fichiers de grandes tailles avec GridFS. Par contre pas de transactionnalité excepté au niveau du document, ce qui va nécessiter de recourir à certaines astuces pour gérer la cohérence de nos données. ",{"type":29,"tag":112,"props":429,"children":430},{},[431],{"type":47,"value":432},"Explication",{"type":47,"value":434},". Tout d’abord s’il n’y a pas de transaction lorsqu’on agit sur plusieurs documents, on a tout de même des \"transactions\" au niveau document. Ca tombe bien, cette première stratégie consiste donc à stocker des documents Json contenant votre entité et ses relations et c’est exactement ce qui nous convient pour notre relation entre Profile et Adress. Exemple :",{"type":29,"tag":30,"props":436,"children":437},{},[438],{"type":47,"value":439},"{ _id : 1 , login: “login1”, address : { zipCode : “69003”}}",{"type":29,"tag":30,"props":441,"children":442},{},[443],{"type":47,"value":444},"Ici, mon entité inclut un attribut address qui aurait pu être stocké dans une table à part avec un modèle relationnel classique.",{"type":29,"tag":30,"props":446,"children":447},{},[448,450],{"type":47,"value":449},"D’autres techniques décrite dans la doc permettent d’envisager des “transactions” applicatives : ",{"type":29,"tag":34,"props":451,"children":454},{"href":452,"rel":453},"http://docs.mongodb.org/manual/tutorial/perform-two-phase-commits/",[38],[455],{"type":47,"value":452},{"type":29,"tag":30,"props":457,"children":458},{},[459],{"type":47,"value":460},"Si vous en êtes là, peut être faut-il quand même se poser des questions...",{"type":29,"tag":30,"props":462,"children":463},{},[464],{"type":47,"value":465},"Pour mes tests j’ai souhaité utiliser Jongo et Morphia, deux librairies avec des approches relativement différentes. La première va rechercher la performance en restant très proche du protocole. La seconde va proposer plus de simplicité d’utilisation via un mapping document objet.",{"type":29,"tag":259,"props":467,"children":469},{"id":468},"jongo",[470],{"type":47,"value":471},"Jongo",{"type":29,"tag":30,"props":473,"children":474},{},[475],{"type":47,"value":476},"Jongo reste très proche du shell mongo donc il faut aimer manipuler le json. J’ai été un peu perplexe au début. Je me suis pris quelques murs et puis finalement, avec l’aide de la formation en ligne de 10gen je me suis bien habitué à la syntaxe. Les performances obtenues sont relativement sympa :",{"type":29,"tag":30,"props":478,"children":479},{},[480,485,486,491,493,497,498,502,504,508,509,513,515,519,521,526],{"type":29,"tag":132,"props":481,"children":482},{},[483],{"type":47,"value":484},"JongoTest",{"type":47,"value":318},{"type":29,"tag":132,"props":487,"children":488},{},[489],{"type":47,"value":490},"0.01",{"type":47,"value":492}," [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 0, GC.time: 0.00, time.total: 0.17, time.warmup: 0.10, time.bench: 0.07 ",{"type":29,"tag":132,"props":494,"children":495},{},[496],{"type":47,"value":484},{"type":47,"value":331},{"type":29,"tag":132,"props":499,"children":500},{},[501],{"type":47,"value":490},{"type":47,"value":503}," [+- 0.01], round.gc: 0.00 [+- 0.00], GC.calls: 1, GC.time: 0.02, time.total: 0.18, time.warmup: 0.06, time.bench: 0.12 ",{"type":29,"tag":132,"props":505,"children":506},{},[507],{"type":47,"value":484},{"type":47,"value":344},{"type":29,"tag":132,"props":510,"children":511},{},[512],{"type":47,"value":323},{"type":47,"value":514}," [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 1, GC.time: 0.01, time.total: 0.52, time.warmup: 0.22, time.bench: 0.29 ",{"type":29,"tag":132,"props":516,"children":517},{},[518],{"type":47,"value":484},{"type":47,"value":520},".testGeoSpatialSearch: [measured 10 out of 15 rounds, threads: 1 (sequential)] round: ",{"type":29,"tag":132,"props":522,"children":523},{},[524],{"type":47,"value":525},"0.21",{"type":47,"value":527}," [+- 0.03], round.gc: 0.00 [+- 0.00], GC.calls: 3, GC.time: 0.15, time.total: 3.81, time.warmup: 1.67, time.bench: 2.14",{"type":29,"tag":30,"props":529,"children":530},{},[531],{"type":29,"tag":34,"props":532,"children":535},{"href":533,"rel":534},"https://bitbucket.org/hlassiege/nosql/src/821b12c7c105/src/test/java/com/sandbox/JongoTest.java?at=default",[38],[536],{"type":47,"value":537},"Le code complet sous bitbucket",{"type":29,"tag":30,"props":539,"children":540},{},[541],{"type":47,"value":542},"Quelques exemple de code :",{"type":29,"tag":223,"props":544,"children":546},{"code":545},"\n    return profiles.find(\"{login:#}\",login).as(Profile.class);\n    return profiles.find(\"{address.loc : {$near: [0, 0], $maxDistance: 5}}\").as(Profile.class);\n",[547],{"type":29,"tag":228,"props":548,"children":549},{"__ignoreMap":7},[550],{"type":47,"value":545},{"type":29,"tag":259,"props":552,"children":554},{"id":553},"morphia",[555],{"type":47,"value":556},"Morphia",{"type":29,"tag":30,"props":558,"children":559},{},[560],{"type":47,"value":561},"Pour tout dire, nous avions choisi Jongo au début suite aux premières phases de ce bench et à l’époque j’avais obtenu un facteur de 1 à 10 entre Jongo et Morphia. Sauf que maintenant que je maîtrise mieux les deux APIs et les réglages, les dernières tests montrent une autre réalité :",{"type":29,"tag":30,"props":563,"children":564},{},[565,570,571,576,578,582,583,587,589,593,594,598,600,604,605,610],{"type":29,"tag":132,"props":566,"children":567},{},[568],{"type":47,"value":569},"MorphiaTest",{"type":47,"value":318},{"type":29,"tag":132,"props":572,"children":573},{},[574],{"type":47,"value":575},"0.02",{"type":47,"value":577}," [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 0, GC.time: 0.00, time.total: 0.34, time.warmup: 0.14, time.bench: 0.21 ",{"type":29,"tag":132,"props":579,"children":580},{},[581],{"type":47,"value":569},{"type":47,"value":331},{"type":29,"tag":132,"props":584,"children":585},{},[586],{"type":47,"value":490},{"type":47,"value":588}," [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 0, GC.time: 0.00, time.total: 0.15, time.warmup: 0.06, time.bench: 0.08 ",{"type":29,"tag":132,"props":590,"children":591},{},[592],{"type":47,"value":569},{"type":47,"value":344},{"type":29,"tag":132,"props":595,"children":596},{},[597],{"type":47,"value":575},{"type":47,"value":599}," [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 0, GC.time: 0.00, time.total: 0.28, time.warmup: 0.11, time.bench: 0.17 ",{"type":29,"tag":132,"props":601,"children":602},{},[603],{"type":47,"value":569},{"type":47,"value":520},{"type":29,"tag":132,"props":606,"children":607},{},[608],{"type":47,"value":609},"0.18",{"type":47,"value":611}," [+- 0.04], round.gc: 0.00 [+- 0.00], GC.calls: 2, GC.time: 0.14, time.total: 2.93, time.warmup: 1.15, time.bench: 1.78",{"type":29,"tag":30,"props":613,"children":614},{},[615],{"type":47,"value":616},"Pour le coup, l'API fait vraiment penser à un O(object) D(document) M(Mapping) et on s'éloigne beaucoup plus du protocole.",{"type":29,"tag":30,"props":618,"children":619},{},[620],{"type":29,"tag":34,"props":621,"children":624},{"href":622,"rel":623},"https://bitbucket.org/hlassiege/nosql/src/821b12c7c105/src/test/java/com/sandbox/MorphiaTest.java?at=default",[38],[625],{"type":47,"value":626},"Le code complet sur bitbucket",{"type":29,"tag":30,"props":628,"children":629},{},[630],{"type":47,"value":631},"Quelques exemples :",{"type":29,"tag":223,"props":633,"children":635},{"code":634},"\n        return ds.find(Profile.class).field(\"address.zipCode\").equal(\"94500\").asList();\n        return ds.find(Profile.class).field(\"address.loc\").near(0,0,100).asList();\n",[636],{"type":29,"tag":228,"props":637,"children":638},{"__ignoreMap":7},[639],{"type":47,"value":634},{"type":29,"tag":30,"props":641,"children":642},{},[643],{"type":47,"value":644},"Verdict : Dans les deux cas la mise en place a été très simple. Sur l’aspect performance on reste sur des performances équivalentes. Jongo semble être très souple en restant proche du protocole au détriment par contre d’une lisibilité assez médiocre cependant quand on aborde des requêtes complexes. Avec le recul j’aurais peut être du partir sur du Morphia. Quoi qu’il en soit, utiliser les deux APIs en fonction des besoins ne doit poser aucun souci de toute façon.",{"type":29,"tag":30,"props":646,"children":647},{},[648,650,655],{"type":47,"value":649},"Dernier point, en terme de fonctionnalités il me manque encore des capacités de recherche full-text digne de ce nom. Du coup en s’inspirant de ce que beaucoup d’autres ont fait avant nous, nous allons coupler notre solution avec du ",{"type":29,"tag":132,"props":651,"children":652},{},[653],{"type":47,"value":654},"Lucene",{"type":47,"value":656},".",{"type":29,"tag":99,"props":658,"children":660},{"id":659},"mongo-et-lucene",[661],{"type":47,"value":662},"Mongo et Lucene",{"type":29,"tag":30,"props":664,"children":665},{},[666],{"type":47,"value":667},"Lucene est un superbe outil spécialisé sur la recherche. En terme de fonctionnalités on va retrouver tout ce qui nous intéresse : recherche full text, par synonyme, géospatiale, fuzzy etc...",{"type":29,"tag":30,"props":669,"children":670},{},[671],{"type":47,"value":672},"Tout d’abord, enfonçons des portes ouvertes, on y stocke des documents, on les lit, les supprime, les modifie, oui c’est une forme de bases de données pour ceux qui en douteraient encore.",{"type":29,"tag":30,"props":674,"children":675},{},[676],{"type":47,"value":677},"Du coup, si c’est une base de données et qu’on y trouve toutes les fonctionnalités, pourquoi ne pas en faire notre stockage primaire ?",{"type":29,"tag":30,"props":679,"children":680},{},[681,683,689],{"type":47,"value":682},"La première fois que JB m’a parlé d’utiliser Lucene + Mongo ou Redis j’avoue ne pas avoir bien compris le but. Pourquoi deux modes de stockage ? Même après la présentation faite au JUG par Xebia ",{"type":29,"tag":34,"props":684,"children":687},{"href":685,"rel":686},"http://www.parisjug.org/xwiki/bin/view/Meeting/20120703",[38],[688],{"type":47,"value":685},{"type":47,"value":690}," je n’avais pas encore le recul nécessaire. Et oui, il a fallu que je pratique car je fais partie des personnes qui comprennent vite quand on leur explique longtemps ^^",{"type":29,"tag":30,"props":692,"children":693},{},[694],{"type":29,"tag":34,"props":695,"children":698},{"href":696,"rel":697},"http://hakanai.free.fr/index.php/nosql-4-bases-a-la-loupe-24/mongo-lucene/",[38],[699],{"type":29,"tag":41,"props":700,"children":703},{"alt":7,"src":701,"title":702},"/images/mongo.lucene-300x91.png","mongo.lucene",[],{"type":29,"tag":30,"props":705,"children":706},{},[707,709,714,716,721],{"type":47,"value":708},"Effectivement ma première idée lorsque j’ai testé Lucene c’était de l’utiliser comme stockage primaire. Sans entrer dans les détails Lucene fait bien la différence entre le ",{"type":29,"tag":132,"props":710,"children":711},{},[712],{"type":47,"value":713},"stockage",{"type":47,"value":715}," d’une donnée, qui permet donc d’utiliser Lucene comme un entrepôt de données, et ",{"type":29,"tag":132,"props":717,"children":718},{},[719],{"type":47,"value":720},"l’indexation",{"type":47,"value":722}," d’une donnée qui la rend disponible pour la recherche. Dans notre cas, il suffisait de stocker la donner en plus de l’indexer.",{"type":29,"tag":30,"props":724,"children":725},{},[726],{"type":47,"value":727},"J’ai donc cherché et lu pas mal d’articles indiquant que la bonne pratique c’était de n’utiliser Lucene que pour rechercher des ID.",{"type":29,"tag":30,"props":729,"children":730},{},[731,735],{"type":29,"tag":112,"props":732,"children":733},{},[734],{"type":47,"value":432},{"type":47,"value":656},{"type":29,"tag":30,"props":737,"children":738},{},[739],{"type":47,"value":740},"Lucene est optimisé pour les recherches, moins pour manipuler de la donnée et pas forcément la meilleure solution lorsqu’il s’agit de mettre à jour ces données régulièrement. De plus si on stocke chaque information un index lucene peut vite prendre la place. Mongo propose moins de fonctionnalités de recherche mais permet de manipuler des données efficacement.",{"type":29,"tag":30,"props":742,"children":743},{},[744],{"type":47,"value":745},"La pratique courante donc c’est de profiter des capacités de recherche de Lucene et de l’efficacité de Mongo pour le stockage. On stocke uniquement les ID de nos entités sous Lucene et on indexe toutes les propriétés nécessaires à la recherche. Le stockage s’effectue donc sous Mongo. Les recherches permettent de récupérer des ID qui permettront par la suite d’aller chercher nos enregistrements dans Mongo.",{"type":29,"tag":30,"props":747,"children":748},{},[749],{"type":29,"tag":34,"props":750,"children":753},{"href":751,"rel":752},"http://hakanai.free.fr/index.php/nosql-4-bases-a-la-loupe-24/mongo-lucene2/",[38],[754],{"type":29,"tag":41,"props":755,"children":758},{"alt":7,"src":756,"title":757},"/images/mongo.lucene2-300x294.png","mongo.lucene2",[],{"type":29,"tag":30,"props":760,"children":761},{},[762],{"type":47,"value":763},"Cool, en tout cas une chose était sure, le projet se ferait avec Lucene.",{"type":29,"tag":30,"props":765,"children":766},{},[767],{"type":47,"value":768},"Billet suivant nous verrons que les choses n’étant jamais simples on ne n’est pas contenté de Lucene.",{"type":29,"tag":30,"props":770,"children":771},{},[772],{"type":47,"value":773},"Pour voir chaque billet :",{"type":29,"tag":59,"props":775,"children":776},{},[777,786,796,807],{"type":29,"tag":63,"props":778,"children":779},{},[780],{"type":29,"tag":34,"props":781,"children":783},{"href":90,"rel":782,"title":92},[38],[784],{"type":47,"value":785},"L'intro",{"type":29,"tag":63,"props":787,"children":788},{},[789],{"type":29,"tag":34,"props":790,"children":793},{"href":791,"rel":792,"title":8},"http://hakanai.free.fr/index.php/nosql-4-bases-a-la-loupe-24/",[38],[794],{"type":47,"value":795},"Redis et Mongo",{"type":29,"tag":63,"props":797,"children":798},{},[799],{"type":29,"tag":34,"props":800,"children":804},{"href":801,"rel":802,"title":803},"http://hakanai.free.fr/index.php/nosql-4-bases-a-la-loupe-34/",[38],"Nosql, 4 bases à la loupe 3/4",[805],{"type":47,"value":806},"ElasticSearch et Solr",{"type":29,"tag":63,"props":808,"children":809},{},[810],{"type":29,"tag":34,"props":811,"children":814},{"href":812,"rel":813},"http://hakanai.free.fr/index.php/nosql-4-bases-a-la-loupe-44/",[38],[815],{"type":47,"value":816},"Le récap",{"title":7,"searchDepth":818,"depth":818,"links":819},2,[820,822,823],{"id":17,"depth":821,"text":67},3,{"id":16,"depth":821,"text":82},{"id":659,"depth":821,"text":662},"markdown","content:articles:2012:11:11:nosql-4-bases-a-la-loupe-24.md","content","articles/2012/11/11/nosql-4-bases-a-la-loupe-24.md","md",1699949297502]